{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8f6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# from helpers import plot_basketball_court\n",
    "\n",
    "locations = pd.read_csv('raw-data/train_locs.csv')\n",
    "play_by_play = pd.read_csv('raw-data/train_pbp.csv')\n",
    "\n",
    "#Feels like its cheating the problem at hand to predict based on teams or conferences\n",
    "play_by_play = play_by_play.drop(['team', 'opponent', 'conference', 'opp_conference'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e05085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  is_oreb    court_x    court_y annotation_code\n",
      "0           2-2        0  72.807686  37.409669              d1\n",
      "1           2-2        0  79.080643  31.477796              d2\n",
      "2           2-2        0  69.956321  24.467300              d3\n",
      "3           2-2        0  75.468933  13.861763              d4\n",
      "4           2-2        0  84.973496  19.254422              d5\n",
      "...         ...      ...        ...        ...             ...\n",
      "308045  5020-52        0  70.669644   7.270347               s\n",
      "308046  5020-52        0  86.958520   4.382292              t1\n",
      "308047  5020-52        0  58.962087  26.764930              t2\n",
      "308048  5020-52        0  76.777949  20.427222              t3\n",
      "308049  5020-52        0  81.019852  44.975904              t4\n",
      "\n",
      "[308050 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Combine CSV data into one large table\n",
    "merged_df = pd.merge(play_by_play, locations, on='id', how='inner')\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20821d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  is_oreb    court_x    court_y annotation_code\n",
      "0           2-2        0  21.192314  37.409669              d1\n",
      "1           2-2        0  14.919357  31.477796              d2\n",
      "2           2-2        0  24.043679  24.467300              d3\n",
      "3           2-2        0  18.531067  13.861763              d4\n",
      "4           2-2        0   9.026504  19.254422              d5\n",
      "...         ...      ...        ...        ...             ...\n",
      "308045  5020-52        0  23.330356   7.270347               s\n",
      "308046  5020-52        0   7.041480   4.382292              t1\n",
      "308047  5020-52        0  35.037913  26.764930              t2\n",
      "308048  5020-52        0  17.222051  20.427222              t3\n",
      "308049  5020-52        0  12.980148  44.975904              t4\n",
      "\n",
      "[308050 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Convert coordinates to only reference one direction of the court\n",
    "#For now lets assume that if the shooter is on the right side of the court, the right basket is the target\n",
    "#Ignore half court shots+ for now\n",
    "#If the shooter has x greater than 47, mirror all points\n",
    "shooter_locations = locations[(locations['annotation_code'] == 's')]\n",
    "merged_df_2 = pd.merge(merged_df, shooter_locations, on='id', how='inner', suffixes=('', '_shooter'))\n",
    "#if merged_df_2['court_x_shooter'] > 47, then mirror court_x to be 94 - court_x\n",
    "merged_df_2['court_x'] = merged_df_2.apply(lambda x: 94 - x['court_x'] if x['court_x_shooter'] > 47 else x['court_x'], axis=1)\n",
    "cleaned_data = merged_df_2.drop(['court_x_shooter', 'court_y_shooter', 'annotation_code_shooter'], axis=1)\n",
    "#Note - some plays don't have a shooter and get removed\n",
    "print(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37ae27de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  is_oreb    court_x    court_y annotation_code        dtb\n",
      "50483    1194-4        1   4.130788  25.002102              d4   0.130805\n",
      "136781   3138-2        0   3.855041  25.001898              d2   0.144971\n",
      "135335   3105-3        0   3.907463  24.888103               s   0.145204\n",
      "238528  4472-24        1   4.095318  24.882916              t3   0.150977\n",
      "277578   4861-3        0   3.921562  24.868055              t3   0.153499\n",
      "...         ...      ...        ...        ...             ...        ...\n",
      "184033  4000-28        0  86.758694  30.361737              d4  82.932199\n",
      "263521  4717-40        0  84.417729   4.123958              d2  83.083213\n",
      "263527  4717-40        0  86.473980  12.642430              t2  83.394646\n",
      "184036  4000-28        0  88.125000  30.878540              t1  84.330142\n",
      "263524  4717-40        0  90.292729  45.420207              d5  88.675926\n",
      "\n",
      "[308050 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#add a column for dtb (distance to basket)\n",
    "cleaned_data['dtb'] = np.linalg.norm(cleaned_data[['court_x', 'court_y']].values - [4, 25], axis=1)\n",
    "print(cleaned_data.sort_values(by=['dtb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51af3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add rankings\n",
    "cleaned_data['dtb_rank'] = cleaned_data.groupby(['id'])['dtb'].rank(method=\"first\").astype(int)\n",
    "cleaned_data['team'] = np.where(cleaned_data['annotation_code'].str.contains('d'), \"Defense\", \"Offense\")\n",
    "cleaned_data['dtb_team_rank'] = cleaned_data.groupby(['id', 'team'])['dtb'].rank(method=\"first\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea1247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the dataframe for each play\n",
    "pivot_df = cleaned_data.pivot_table(index=['id', 'is_oreb'], columns=['annotation_code'], values=['court_x', 'court_y', 'dtb'])\n",
    "pivot_df.columns = ['{}_{}'.format(col[0], col[1]) for col in pivot_df.columns]\n",
    "pivot_df = pivot_df.reset_index()\n",
    "\n",
    "pivot_df_2 = cleaned_data.pivot_table(index=['id', 'is_oreb'], columns=['dtb_rank'], values=['dtb'])\n",
    "pivot_df_2.columns = ['{}_{}'.format(col[0], col[1]) for col in pivot_df_2.columns]\n",
    "pivot_df_2 = pivot_df_2.reset_index()\n",
    "\n",
    "pivot_df_3 = cleaned_data.pivot_table(index=['id', 'is_oreb'], columns=['dtb_team_rank', 'team'], values=['dtb'])\n",
    "pivot_df_3.columns = ['{}_{}_{}'.format(col[0], col[1], col[2]) for col in pivot_df_3.columns]\n",
    "pivot_df_3 = pivot_df_3.reset_index()\n",
    "\n",
    "pivot_df = pd.merge(pivot_df, pivot_df_2, on=['id', 'is_oreb'], how='inner')\n",
    "pivot_df = pd.merge(pivot_df, pivot_df_3, on=['id', 'is_oreb'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99dc6cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id  is_oreb  court_x_d1  court_x_d2  court_x_d3  court_x_d4  \\\n",
      "0      10-10        0   16.757017   20.172220   13.667048   11.552852   \n",
      "1      10-12        0    7.229075    7.038597    9.324267   19.419485   \n",
      "2      10-13        0   26.028072    8.849291   14.908529    8.849291   \n",
      "3       10-3        0   16.427338   12.561111   20.535393    8.937342   \n",
      "4       10-6        0   21.055481   34.011315   12.042747   15.140892   \n",
      "...      ...      ...         ...         ...         ...         ...   \n",
      "30800  998-6        0    6.761558   19.689568    5.915878   11.836204   \n",
      "30801  999-1        0   19.336079   23.806515    8.220410    9.670299   \n",
      "30802  999-3        0   12.275106    6.344312   17.065397   19.574608   \n",
      "30803  999-4        0    7.416399    8.556974   22.243458   22.927847   \n",
      "30804  999-5        0    6.546554    6.755028   20.097206   20.514160   \n",
      "\n",
      "       court_x_d5  court_x_s  court_x_t1  court_x_t2  ...  top6_any_dtb  \\\n",
      "0       12.853857  27.490582   18.545910   28.303701  ...     72.479066   \n",
      "1       18.276686   7.990918   18.848122   27.229033  ...     54.255719   \n",
      "2       15.069376  25.880695    6.065335   21.622826  ...     71.415576   \n",
      "3       16.427972  17.272501   13.044335   29.720155  ...     69.320727   \n",
      "4        9.930412  28.378357   25.421066   20.773849  ...     88.294119   \n",
      "...           ...        ...         ...         ...  ...           ...   \n",
      "30800   21.743523   6.882469   27.905533    6.399101  ...     54.819980   \n",
      "30801   17.161282  21.631718    4.112428   31.660026  ...     86.829549   \n",
      "30802    7.074240   8.169133   10.450213   15.696764  ...     57.258008   \n",
      "30803   22.927847   9.697479    9.925609   12.662877  ...     69.244963   \n",
      "30804   12.487961   4.044869   23.331094    9.568907  ...     77.161771   \n",
      "\n",
      "       top7_any_dtb  top8_any_dtb  top9_any_dtb  count_less_than_5  \\\n",
      "0         88.654138    111.827447    137.138713                  0   \n",
      "1         72.010319     92.982111    116.228907                  2   \n",
      "2         93.193959    116.184237    139.380109                  0   \n",
      "3         91.423022    113.583158    138.057138                  0   \n",
      "4        112.403949    137.414207    165.983254                  0   \n",
      "...             ...           ...           ...                ...   \n",
      "30800     73.230342     96.209941    122.144856                  0   \n",
      "30801    107.626702    130.904842    158.510511                  0   \n",
      "30802     72.960892     96.609838    122.737121                  0   \n",
      "30803     91.743795    115.066201    142.600744                  0   \n",
      "30804     97.965990    120.443546    144.182320                  0   \n",
      "\n",
      "       count_less_than_5_offense  count_less_than_5_defense  \\\n",
      "0                              0                          0   \n",
      "1                              0                          1   \n",
      "2                              0                          0   \n",
      "3                              0                          0   \n",
      "4                              0                          0   \n",
      "...                          ...                        ...   \n",
      "30800                          0                          0   \n",
      "30801                          0                          0   \n",
      "30802                          0                          0   \n",
      "30803                          0                          0   \n",
      "30804                          0                          0   \n",
      "\n",
      "       count_less_than_10  count_less_than_10_offense  \\\n",
      "0                       0                           0   \n",
      "1                       2                           0   \n",
      "2                       0                           0   \n",
      "3                       0                           0   \n",
      "4                       0                           0   \n",
      "...                   ...                         ...   \n",
      "30800                   0                           0   \n",
      "30801                   0                           0   \n",
      "30802                   0                           0   \n",
      "30803                   0                           0   \n",
      "30804                   0                           0   \n",
      "\n",
      "       count_less_than_10_defense  \n",
      "0                               0  \n",
      "1                               1  \n",
      "2                               0  \n",
      "3                               0  \n",
      "4                               0  \n",
      "...                           ...  \n",
      "30800                           0  \n",
      "30801                           0  \n",
      "30802                           0  \n",
      "30803                           0  \n",
      "30804                           0  \n",
      "\n",
      "[30805 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "#Add some aggregate columns\n",
    "pivot_df['total_offense_dtb'] = pivot_df[[\"dtb_t1\", \"dtb_t2\", \"dtb_t3\", \"dtb_t4\", \"dtb_s\"]].sum(axis=1)\n",
    "pivot_df['total_defense_dtb'] = pivot_df[[\"dtb_d1\", \"dtb_d2\", \"dtb_d3\", \"dtb_d4\", \"dtb_d5\"]].sum(axis=1)\n",
    "pivot_df['top2_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\"]].sum(axis=1)\n",
    "pivot_df['top3_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\"]].sum(axis=1)\n",
    "pivot_df['top4_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\"]].sum(axis=1)\n",
    "pivot_df['top2_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\"]].sum(axis=1)\n",
    "pivot_df['top3_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\"]].sum(axis=1)\n",
    "pivot_df['top4_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\"]].sum(axis=1)\n",
    "pivot_df['top1_any_dtb'] = pivot_df[[\"dtb_1\"]].sum(axis=1)\n",
    "pivot_df['top2_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\"]].sum(axis=1)\n",
    "pivot_df['top3_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\"]].sum(axis=1)\n",
    "pivot_df['top4_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\"]].sum(axis=1)\n",
    "pivot_df['top5_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\"]].sum(axis=1)\n",
    "pivot_df['top6_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\"]].sum(axis=1)\n",
    "pivot_df['top7_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\"]].sum(axis=1)\n",
    "pivot_df['top8_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\"]].sum(axis=1)\n",
    "pivot_df['top9_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\", \"dtb_9\"]].sum(axis=1)\n",
    "count_less_than_5 = lambda row: sum(row < 5)\n",
    "pivot_df['count_less_than_5'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\", \"dtb_9\", 'dtb_10']].iloc[:, 1:].apply(count_less_than_5, axis=1)\n",
    "pivot_df['count_less_than_5_offense'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\", \"dtb_5_Offense\"]].iloc[:, 1:].apply(count_less_than_5, axis=1)\n",
    "pivot_df['count_less_than_5_defense'] = pivot_df[[\"dtb_1_Defense\", \"dtb_2_Defense\", \"dtb_3_Defense\", \"dtb_4_Defense\", \"dtb_5_Defense\"]].iloc[:, 1:].apply(count_less_than_5, axis=1)\n",
    "count_less_than_10 = lambda row: sum(row < 5)\n",
    "pivot_df['count_less_than_10'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\", \"dtb_9\", 'dtb_10']].iloc[:, 1:].apply(count_less_than_10, axis=1)\n",
    "pivot_df['count_less_than_10_offense'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\", \"dtb_5_Offense\"]].iloc[:, 1:].apply(count_less_than_10, axis=1)\n",
    "pivot_df['count_less_than_10_defense'] = pivot_df[[\"dtb_1_Defense\", \"dtb_2_Defense\", \"dtb_3_Defense\", \"dtb_4_Defense\", \"dtb_5_Defense\"]].iloc[:, 1:].apply(count_less_than_10, axis=1)\n",
    "\n",
    "\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d898bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dapomeranz/.pyenv/versions/final-project-3.10.4/lib/python3.10/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "2023-07-20 16:11:20.921752: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054/2054 [==============================] - 13s 6ms/step - loss: 0.6198 - accuracy: 0.6993\n",
      " 104/1027 [==>...........................] - ETA: 1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 16:11:34.042289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 594/1027 [================>.............] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pivot_df.drop(['id', 'is_oreb'], axis=1)\n",
    "Y = pivot_df['is_oreb']\n",
    "\n",
    "# Create a SimpleImputer instance to replace NaN values with the mean of the column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "X = imputer.fit_transform(X)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "training_images, testing_images, training_labels, testing_labels = train_test_split(X, \n",
    "                                                                   Y,\n",
    "                                                                   test_size=0.2,\n",
    "                                                                   shuffle=True,\n",
    "                                                                   random_state=0)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Custom wrapper function for your Keras model with two parameters\n",
    "def create_model(batch_size=32):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(40, input_shape=(70,), activation='relu'))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dense(batch_size, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the batch sizes you want to try\n",
    "batch_sizes = list(range(8, 257, 8))\n",
    "\n",
    "# Create the KerasClassifier\n",
    "keras_classifier = KerasClassifier(build_fn=create_model, verbose=1)\n",
    "\n",
    "# Create a parameter grid to search over\n",
    "param_grid = dict(batch_size=batch_sizes)\n",
    "\n",
    "# Create the GridSearchCV instance\n",
    "grid = GridSearchCV(estimator=keras_classifier, param_grid=param_grid, cv=3)\n",
    "\n",
    "# Fit the grid search on your data\n",
    "grid_result = grid.fit(training_images, training_labels)\n",
    "\n",
    "# Print the best results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e51d77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m random_labels \u001b[38;5;241m=\u001b[39m Y[random_indices]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Get predictions for the random samples using the trained model\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(random_samples)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Print the random samples, their corresponding actual labels from Y, and the model predictions\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_random_samples):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate 5 random indices to select samples from X\n",
    "num_random_samples = 5\n",
    "random_indices = np.random.choice(X.shape[0], num_random_samples, replace=False)\n",
    "# Select random samples from X and corresponding labels from Y using the random indices\n",
    "random_samples = X[random_indices]\n",
    "random_labels = Y[random_indices]\n",
    "# Get predictions for the random samples using the trained model\n",
    "predictions = model.predict(random_samples)\n",
    "# Print the random samples, their corresponding actual labels from Y, and the model predictions\n",
    "for i in range(num_random_samples):\n",
    "    print(\"Random Sample {}: Actual Label: {}  Prediction: {:.2f}\".format(\n",
    "        i+1, random_labels.iloc[i], predictions[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b1620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import plot_basketball_court\n",
    "locations = pd.read_csv('raw-data/test_locs.csv')\n",
    "play_by_play = pd.read_csv('raw-data/test_pbp.csv')\n",
    "print(play_by_play.shape)\n",
    "#Feels like its cheating the problem at hand to predict based on teams or conferences\n",
    "play_by_play = play_by_play.drop(['team', 'opponent', 'conference', 'opp_conference'], axis=1)\n",
    "#Combine CSV data into one large table\n",
    "merged_df = pd.merge(play_by_play, locations, on='id', how='left')\n",
    "print(locations.shape)\n",
    "print(play_by_play.shape)\n",
    "#If the shooter has x greater than 47, mirror all points\n",
    "shooter_locations = locations[(locations['annotation_code'] == 's')]\n",
    "merged_df_2 = pd.merge(merged_df, shooter_locations, on='id', how='left', suffixes=('', '_shooter'))\n",
    "#if merged_df_2['court_x_shooter'] > 47, then mirror court_x to be 94 - court_x\n",
    "merged_df_2['court_x'] = merged_df_2.apply(lambda x: 94 - x['court_x'] if x['court_x_shooter'] > 47 else x['court_x'], axis=1)\n",
    "cleaned_data = merged_df_2.drop(['court_x_shooter', 'court_y_shooter', 'annotation_code_shooter'], axis=1)\n",
    "#add a column for dtb (distance to basket)\n",
    "cleaned_data['dtb'] = np.linalg.norm(cleaned_data[['court_x', 'court_y']].values - [4, 25], axis=1)\n",
    "# Add rankings\n",
    "cleaned_data['dtb_rank'] = cleaned_data.groupby(['id'])['dtb'].rank(method=\"first\").astype(int)\n",
    "cleaned_data['team'] = np.where(cleaned_data['annotation_code'].str.contains('d'), \"Defense\", \"Offense\")\n",
    "cleaned_data['dtb_team_rank'] = cleaned_data.groupby(['id', 'team'])['dtb'].rank(method=\"first\").astype(int)\n",
    "# Pivot the dataframe for each play\n",
    "pivot_df = cleaned_data.pivot_table(index=['id'], columns=['annotation_code'], values=['court_x', 'court_y', 'dtb'])\n",
    "pivot_df.columns = ['{}_{}'.format(col[0], col[1]) for col in pivot_df.columns]\n",
    "pivot_df = pivot_df.reset_index()\n",
    "pivot_df_2 = cleaned_data.pivot_table(index=['id'], columns=['dtb_rank'], values=['dtb'])\n",
    "pivot_df_2.columns = ['{}_{}'.format(col[0], col[1]) for col in pivot_df_2.columns]\n",
    "pivot_df_2 = pivot_df_2.reset_index()\n",
    "pivot_df_3 = cleaned_data.pivot_table(index=['id'], columns=['dtb_team_rank', 'team'], values=['dtb'])\n",
    "pivot_df_3.columns = ['{}_{}_{}'.format(col[0], col[1], col[2]) for col in pivot_df_3.columns]\n",
    "pivot_df_3 = pivot_df_3.reset_index()\n",
    "pivot_df = pd.merge(pivot_df, pivot_df_2, on=['id'], how='left')\n",
    "pivot_df = pd.merge(pivot_df, pivot_df_3, on=['id'], how='left')\n",
    "#Add some aggregate columns\n",
    "pivot_df['total_offense_dtb'] = pivot_df[[\"dtb_t1\", \"dtb_t2\", \"dtb_t3\", \"dtb_t4\", \"dtb_s\"]].sum(axis=1)\n",
    "pivot_df['total_defense_dtb'] = pivot_df[[\"dtb_d1\", \"dtb_d2\", \"dtb_d3\", \"dtb_d4\", \"dtb_d5\"]].sum(axis=1)\n",
    "pivot_df['top2_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\"]].sum(axis=1)\n",
    "pivot_df['top3_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\"]].sum(axis=1)\n",
    "pivot_df['top4_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\"]].sum(axis=1)\n",
    "pivot_df['top2_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\"]].sum(axis=1)\n",
    "pivot_df['top3_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\"]].sum(axis=1)\n",
    "pivot_df['top4_offense_dtb'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\"]].sum(axis=1)\n",
    "pivot_df['top1_any_dtb'] = pivot_df[[\"dtb_1\"]].sum(axis=1)\n",
    "pivot_df['top2_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\"]].sum(axis=1)\n",
    "pivot_df['top3_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\"]].sum(axis=1)\n",
    "pivot_df['top4_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\"]].sum(axis=1)\n",
    "pivot_df['top5_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\"]].sum(axis=1)\n",
    "pivot_df['top6_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\"]].sum(axis=1)\n",
    "pivot_df['top7_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\"]].sum(axis=1)\n",
    "pivot_df['top8_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\"]].sum(axis=1)\n",
    "pivot_df['top9_any_dtb'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\", \"dtb_9\"]].sum(axis=1)\n",
    "count_less_than_5 = lambda row: sum(row < 5)\n",
    "pivot_df['count_less_than_5'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\", \"dtb_9\", 'dtb_10']].iloc[:, 1:].apply(count_less_than_5, axis=1)\n",
    "pivot_df['count_less_than_5_offense'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\", \"dtb_5_Offense\"]].iloc[:, 1:].apply(count_less_than_5, axis=1)\n",
    "pivot_df['count_less_than_5_defense'] = pivot_df[[\"dtb_1_Defense\", \"dtb_2_Defense\", \"dtb_3_Defense\", \"dtb_4_Defense\", \"dtb_5_Defense\"]].iloc[:, 1:].apply(count_less_than_5, axis=1)\n",
    "count_less_than_10 = lambda row: sum(row < 5)\n",
    "pivot_df['count_less_than_10'] = pivot_df[[\"dtb_1\", \"dtb_2\", \"dtb_3\", \"dtb_4\", \"dtb_5\", \"dtb_6\", \"dtb_7\", \"dtb_8\", \"dtb_9\", 'dtb_10']].iloc[:, 1:].apply(count_less_than_10, axis=1)\n",
    "pivot_df['count_less_than_10_offense'] = pivot_df[[\"dtb_1_Offense\", \"dtb_2_Offense\", \"dtb_3_Offense\", \"dtb_4_Offense\", \"dtb_5_Offense\"]].iloc[:, 1:].apply(count_less_than_10, axis=1)\n",
    "pivot_df['count_less_than_10_defense'] = pivot_df[[\"dtb_1_Defense\", \"dtb_2_Defense\", \"dtb_3_Defense\", \"dtb_4_Defense\", \"dtb_5_Defense\"]].iloc[:, 1:].apply(count_less_than_10, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2434656",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pivot_df.drop(['id'], axis=1)\n",
    "\n",
    "# Create a SimpleImputer instance to replace NaN values with the mean of the column\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "scaler = StandardScaler()\n",
    "X = imputer.fit_transform(X)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "Yhat = model.predict(X)\n",
    "\n",
    "result_pivot_df = pivot_df\n",
    "result_pivot_df['pred'] = Yhat\n",
    "\n",
    "result_pivot_df['pred'] = result_pivot_df['pred'].apply(lambda x: round(x, 3))\n",
    "\n",
    "# Print the resulting DataFrame with 'id' and 'Yhat' columns\n",
    "print(result_pivot_df[['id', 'pred']])\n",
    "result_pivot_df[['id', 'pred']].to_csv('entry1.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0651f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project",
   "language": "python",
   "name": "final-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
